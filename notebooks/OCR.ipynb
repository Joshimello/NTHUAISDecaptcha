{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewlduy0zbHXN"
      },
      "outputs": [],
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflowjs\n",
        "!pip install jax==0.4.21\n",
        "!pip install jaxlib==0.4.21\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflowjs as tfjs\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_segments(image):\n",
        "    x, y, w, h = cv2.boundingRect(image)\n",
        "    segments = []\n",
        "\n",
        "    def recursive_split(x, y, w, h):\n",
        "        if w > h-5:\n",
        "            mid = x + w // 2\n",
        "            recursive_split(x, y, mid - x, h)\n",
        "            recursive_split(mid, y, x + w - mid, h)\n",
        "        else:\n",
        "            segments.append((x, y, w, h))\n",
        "\n",
        "    recursive_split(x, y, w, h)\n",
        "    return segments\n",
        "\n",
        "def pad_to_center(image, target_size=(30, 30)):\n",
        "        h, w = image.shape[:2]\n",
        "        dh, dw = target_size[0] - h, target_size[1] - w\n",
        "        top, left = dh // 2, dw // 2\n",
        "        bottom, right = dh - top, dw - left\n",
        "\n",
        "        padding = ((top, bottom), (left, right)) + ((0, 0),) * (image.ndim - 2)\n",
        "        return np.pad(image, padding, 'constant')"
      ],
      "metadata": {
        "id": "BuxrFFS1jV89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = '928153'\n",
        "files = os.listdir(l)\n",
        "for i, file in enumerate(files):\n",
        "    image = cv2.imread(os.path.join(l, f'{i}.png'), 0)\n",
        "    _, image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
        "\n",
        "    digit_images = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "        if w >= 6 and h >= 6:\n",
        "            if w > h:\n",
        "                segments = split_segments(cnt)\n",
        "            else:\n",
        "                segments = [(x, y, w, h)]\n",
        "\n",
        "            for sx, sy, sw, sh in segments:\n",
        "                digit = image[sy:sy+sh, sx:sx+sw]\n",
        "                digit_images.append(digit)\n",
        "\n",
        "    for j, digit in enumerate(digit_images):\n",
        "        digit = pad_to_center(digit)\n",
        "\n",
        "        if not os.path.exists(l[j]):\n",
        "            os.makedirs(l[j])\n",
        "\n",
        "        cv2.imwrite(os.path.join(l[j], f'{i}.png'), digit)"
      ],
      "metadata": {
        "id": "d1gvCYATisVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data.zip ./"
      ],
      "metadata": {
        "id": "3s4WxJBskSUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "bvfszLbmqpml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "srHrOmFyqrY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "\n",
        "def add_noise(img):\n",
        "    rotation_degree = random.randint(-45, 45)\n",
        "    rows, cols, _ = img.shape\n",
        "    M = cv2.getRotationMatrix2D((cols/2, rows/2), rotation_degree, 1)\n",
        "    img = cv2.warpAffine(img, M, (cols, rows))\n",
        "\n",
        "    number_of_lines = random.randint(1, 5)\n",
        "    for _ in range(number_of_lines):\n",
        "        x1, y1 = random.randint(0, cols), random.randint(0, rows)\n",
        "        x2, y2 = random.randint(0, cols), random.randint(0, rows)\n",
        "        img = cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
        "\n",
        "    noise_ratio = 0.3\n",
        "    noise = np.random.choice([0, 1], size=img.shape, p=[1 - noise_ratio, noise_ratio])\n",
        "    mask = np.random.choice([0, 255], size=img.shape, p=[1 - noise_ratio, noise_ratio])\n",
        "    img = np.where(noise == 1, mask, img)\n",
        "    return img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.1,\n",
        "    preprocessing_function=add_noise\n",
        "    )\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    'data',\n",
        "    target_size=(30, 30),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    'data',\n",
        "    target_size=(30, 30),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "id": "LOGmZIIgspe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7826ca6-14b5-445f-c5ab-b5b42b1d0f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 897 images belonging to 10 classes.\n",
            "Found 95 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size)"
      ],
      "metadata": {
        "id": "p2BqwwDjs9Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ALSjNnJWtsf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import itertools\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255, preprocessing_function=add_noise)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'data',\n",
        "    target_size=(30, 30),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(class_labels))\n",
        "plt.xticks(tick_marks, class_labels, rotation=45)\n",
        "plt.yticks(tick_marks, class_labels)\n",
        "\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], fmt),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "report = classification_report(test_generator.classes, predicted_classes)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "Mpb66b98w8ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n",
        "tfjs.converters.save_keras_model(model, \"tfjs.h5\")"
      ],
      "metadata": {
        "id": "oHOFIEsythhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "import io\n",
        "\n",
        "def loadimg(url):\n",
        "    response = requests.get(url)\n",
        "    image_data = response.content\n",
        "    with open('test.png', 'wb') as f:\n",
        "        f.write(image_data)\n",
        "\n",
        "def procimg(img):\n",
        "    image = cv2.imread(img, 0)\n",
        "    _, image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
        "\n",
        "    digit_images = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "        if w >= 6 and h >= 6:\n",
        "            if w > h:\n",
        "                segments = split_segments(cnt)\n",
        "            else:\n",
        "                segments = [(x, y, w, h)]\n",
        "\n",
        "            for sx, sy, sw, sh in segments:\n",
        "                digit = image[sy:sy+sh, sx:sx+sw]\n",
        "                digit_images.append(digit)\n",
        "    return digit_images\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "model = load_model('model.h5')\n",
        "loadimg('https://www.ccxp.nthu.edu.tw/ccxp/INQUIRE/auth_img.php?pwdstr=20240111-789039411757')\n",
        "digits = procimg('test.png')\n",
        "\n",
        "ans = []\n",
        "for i, digit in enumerate(digits):\n",
        "    digit = pad_to_center(digit)\n",
        "    img = cv2.cvtColor(digit, cv2.COLOR_BGR2RGB)\n",
        "    #plt.imshow(img)\n",
        "    #plt.show()\n",
        "    img = cv2.resize(img, (30, 30))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    predictions = model.predict(img)\n",
        "    ans.append(np.argmax(predictions))\n",
        "\n",
        "print(''.join(map(str, ans)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1dtZE2Cu9PL",
        "outputId": "d6269893-35f0-46a3-8c5c-776350c71bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "520205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = load_model('model.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open (\"model.tflite\" , \"wb\") .write(tflite_model)"
      ],
      "metadata": {
        "id": "05kwdvx6NDC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}